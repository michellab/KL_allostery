{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA analysis\n",
    "----\n",
    "\n",
    "----\n",
    "## Introduction \n",
    "\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:DarkRed\"> Some details on trajectory/topology input\n",
    "\n",
    "-------\n",
    "\n",
    "### C$\\alpha$ coordinate PCA\n",
    "#### Simulation input\n",
    "\n",
    "We will input several different simulations into the same PCA, which will have been run with different ligands: \n",
    "\n",
    "<img src='z_images/PCA_input.png' width=\"400\">\n",
    "<br>\n",
    "\n",
    "The trajectories that we input into the PCA must have same topology, so must be processed first to remove all water, ligands, etc.\n",
    "\n",
    "It is also important to do an accurate alignment of all the frames for each trajectory, to the **same starting structure** if carrying out C$\\alpha$ coordinate PCA. Depending on the system, it may make sense to align everything, or only part of the structure. In this case, all C$\\alpha$ were used to align.\n",
    "\n",
    "In the `0_TRAJECTORIES` folder there is a file `first_frame.pdb` - which in each case is the same structure of the protein with ligands, ions and waters removed. Alignment for each trajectory can then be done with cpptraj (but is already done for the tutorial). There are some example scripts in the folder `/Scripts/Traj_processing_scripts`.\n",
    "\n",
    "For this tutorial, we will use every 5th snapshot of a 1$\\mu$s simulation (40,000 frames - original simulation 200,000 frames).\n",
    "\n",
    "Four simulations will be used: \n",
    "\n",
    "* 0_system_A (PDK1 with allosteric inhibitor 1F8 bound. PDB ID 3ORX.)\n",
    "\n",
    "\n",
    "* 1_system_B (PDK1 with allosteric activator 2A2 bound. PDB ID 3ORZ.)\n",
    "\n",
    "\n",
    "* 2_system_C (PDK1 with no allosteric ligand bound.)\n",
    "\n",
    "\n",
    "* 3_system_D (PDK1 with allosteric activator J30 bound. PDB ID 3OTU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:DarkRed\">Some background on PCA\n",
    "    \n",
    "From a set of data $\\begin{equation} X_t\\end{equation}$ which we obtain from the trajectory, we compute the covariance matrix:\n",
    "\n",
    "\\begin{equation}\n",
    "C=(X−μ)^T(X−μ)\n",
    "\\end{equation}\n",
    "\n",
    "and solve  the eigenvalue problem:\n",
    "\\begin{equation}\n",
    "Cr_i=σ_ir_i\n",
    "\\end{equation}\n",
    "\n",
    "$\\begin{equation} r_i \\end{equation}$ are the principal components and $\\begin{equation} σ_i\\end{equation}$ are their respective variances.\n",
    "\n",
    "The input data $\\begin{equation} X_t\\end{equation}$ can be something like C$\\alpha$ coordinates, or backbone or sidechain torsions. \n",
    "\n",
    "In order to compare different simuluations, we do the dimensionality reduction on all available trajectories of the system. In this case, we have 4 different simulations, and will input all into the PCA together. We can then compare the highest variance motions between the different systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduction of dimensionality**\n",
    "\n",
    "This therefore allows a large dimensional dataset (i.e. all C$\\alpha$ coordinates for 40,000 frames) to be reduced into a smaller number of dimensions, where the new set of dimensions should still account for a large amount of the variance. \n",
    "\n",
    "<img src='z_images/PCA_dimensions.png' width=\"400\" >\n",
    "\n",
    "\n",
    "The output of this is a set of principal components, with Principal Component 1 (PC1) having the highest variance, and subsequent PC's having decreasing variance. \n",
    "\n",
    "As a guideline, we usually calculate the first 10 principal components, and we can check how much of the variance these first 10 PCs account for. \n",
    "\n",
    "The following script selects a subset of residues (it excludes the terminal regions of the model protein) and carries out a C$\\alpha$ coordinate PCA. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:DarkRed\">Output from the PCA\n",
    "    \n",
    "The idea is to also use the output from the PCA in calculations of MI (Mutual Infomrmation) or KL (Kullback-Leibler) Divergence, therefore we need to output the values of PC per snapshot for each system, and distributions of these values.\n",
    "\n",
    "The script will output several things: \n",
    "\n",
    "\n",
    "* Frames corresponding to the minimum and maximum values of PC1 and PC2 for each system.\n",
    "\n",
    "\n",
    "* Per atom contribution to PC1 and PC2.\n",
    "\n",
    "\n",
    "* Per snapshot value of PC1 and PC2 for each system.\n",
    "\n",
    "\n",
    "* Distribution of values of PC1 and PC2 for each system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "| Folder name | Allosteric ligand |\n",
    "| :--- | :-: | \n",
    "| 0_system_A | Inhibitor 1F8 |\n",
    "| 1_system_B | Activator 2A2 |\n",
    "| 2_system_C | No ligand |\n",
    "| 3_system_D | Activator J30 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic(u'pylab inline')\n",
    "import pyemma\n",
    "import pyemma.coordinates as coor\n",
    "from pyemma.coordinates import pca\n",
    "import mdtraj as md\n",
    "from pyemma.coordinates import load\n",
    "from pyemma.coordinates import source\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python Scripts/7.PCA_tutorial_CA_coordinates.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit system_list with folder names of different systems.\n",
    "system_list = [\"0_system_A\",\"1_system_B\",\"2_system_C\",\"3_system_D\"]\n",
    "md_data = \"0_TRAJECTORIES\"\n",
    "\n",
    "# Select trajectory:\n",
    "#traj_filename = \"longtraj_aligned_PCA.dcd\"\n",
    "traj_filename = \"short_traj_aligned.dcd\"\n",
    "\n",
    "top = \"%s/%s/topology.parm7\" % (md_data,system_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_sel = \"resid 20 to 180 and name CA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topology = md.load_prmtop(top)\n",
    "\n",
    "print (topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only CA and also not all residues - C-terminal region is large. \n",
    "# This is approx focus on residues around active site, around allosteric site, and between\n",
    "\n",
    "# all CA indices:\n",
    "CA_topo = topology.select(\"name CA\")\n",
    "\n",
    "# selected CA indices\n",
    "atom_selection = topology.select(atom_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list with all file locations of trajectory data\n",
    "all_files_list = []\n",
    "\n",
    "for i in range(0,len(system_list)):\n",
    "    filenames = \"%s/%s/%s\" % (md_data,system_list[i],traj_filename)\n",
    "    all_files_list.append(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (all_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"2_PCA/CA_COOR_OUTPUT\" \n",
    "if not os.path.exists(filename):\n",
    "    cmd = \"mkdir -p %s\" % filename\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = coor.featurizer(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.add_selection(atom_selection)\n",
    "inp = coor.source([all_files_list[0],all_files_list[1],all_files_list[2],all_files_list[3]], features=feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('trajectory length = '),(inp.trajectory_length(0))\n",
    "print ('number of dimensions = '),(inp.dimension())\n",
    "print ('number of trajectories ='),(inp.number_of_trajectories())\n",
    "print ('total number of frames = '),(inp.n_frames_total())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_obj = coor.pca(inp, dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_A_pca_out = pca_obj.get_output()[0]\n",
    "system_B_pca_out = pca_obj.get_output()[1]\n",
    "system_C_pca_out = pca_obj.get_output()[2]\n",
    "system_D_pca_out = pca_obj.get_output()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pc1, min and max values are these frames:\n",
    "A_pc1_max = (argmax(system_A_pca_out[:,0]))\n",
    "A_pc1_min = (argmin(system_A_pca_out[:,0]))\n",
    "\n",
    "B_pc1_max = (argmax(system_B_pca_out[:,0]))\n",
    "B_pc1_min = (argmin(system_B_pca_out[:,0]))\n",
    "\n",
    "C_pc1_max = (argmax(system_C_pca_out[:,0]))\n",
    "C_pc1_min = (argmin(system_C_pca_out[:,0]))\n",
    "\n",
    "D_pc1_max = (argmax(system_D_pca_out[:,0]))\n",
    "D_pc1_min = (argmin(system_D_pca_out[:,0]))\n",
    "\n",
    "system_A_traj = md.load(all_files_list[0],top=topology)\n",
    "system_B_traj = md.load(all_files_list[1],top=topology)\n",
    "system_C_traj = md.load(all_files_list[2],top=topology)\n",
    "system_D_traj = md.load(all_files_list[3],top=topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_A_traj[A_pc1_max].save_pdb(\"%s/A_PC1_max_frame%s.pdb\" % (filename,A_pc1_max))\n",
    "system_A_traj[A_pc1_min].save_pdb(\"%s/A_PC1_min_frame%s.pdb\" % (filename,A_pc1_min))\n",
    "\n",
    "system_B_traj[B_pc1_max].save_pdb(\"%s/B_PC1_max_frame%s.pdb\" % (filename,B_pc1_max))\n",
    "system_B_traj[B_pc1_min].save_pdb(\"%s/B_PC1_min_frame%s.pdb\" % (filename,B_pc1_min))\n",
    "\n",
    "system_C_traj[C_pc1_max].save_pdb(\"%s/C_PC1_max_frame%s.pdb\" % (filename,C_pc1_max))\n",
    "system_C_traj[C_pc1_min].save_pdb(\"%s/C_PC1_min_frame%s.pdb\" % (filename,C_pc1_min))\n",
    "\n",
    "system_D_traj[D_pc1_max].save_pdb(\"%s/D_PC1_max_frame%s.pdb\" % (filename,D_pc1_max))\n",
    "system_D_traj[D_pc1_min].save_pdb(\"%s/D_PC1_min_frame%s.pdb\" % (filename,D_pc1_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc1 - residues 1-264 xyz\n",
    "pc1_ca_contributions = []\n",
    "for i in pca_obj.feature_PC_correlation[:,0]:\n",
    "    pc1_ca_contributions.append(np.absolute(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1_ca_X = np.array(pc1_ca_contributions[0:len(pc1_ca_contributions):3])\n",
    "pc1_ca_Y = np.array(pc1_ca_contributions[1:len(pc1_ca_contributions):3])\n",
    "pc1_ca_Z = np.array(pc1_ca_contributions[2:len(pc1_ca_contributions):3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we don't include all residues in the PCA, we need to assign the per atom contribution to the \n",
    "# correct residue in the topology. To do this, rearrange the data by adding zeros for residues not included in the PCA\n",
    "\n",
    "def rearrange_data(data):\n",
    "    residue_and_per_atom_contribution = np.vstack((atom_selection,data)).T\n",
    "    new_atoms = []\n",
    "    for i in CA_topo:\n",
    "        if i in atom_selection: \n",
    "            new_atoms.append(i)\n",
    "        else:\n",
    "            new_atoms.append(\"--\")\n",
    "    new_data = []\n",
    "    j = 0\n",
    "    for i in range (0,len(CA_topo)):\n",
    "        if CA_topo[i] in residue_and_per_atom_contribution[:,0]:\n",
    "            new_data.append(residue_and_per_atom_contribution[j][1])\n",
    "            j = j + 1 \n",
    "        else:\n",
    "            new_data.append(0.0)\n",
    "    return new_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1_all_ca_contrib = np.vstack((pc1_ca_X,pc1_ca_Y,pc1_ca_Z)).T\n",
    "summed_cont_PC1 = PC1_all_ca_contrib.sum(axis=1)\n",
    "summed_cont_PC1 = rearrange_data(summed_cont_PC1)\n",
    "np.savetxt(\"%s/PC1_atom_contribution.dat\" % filename , summed_cont_PC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(summed_cont_PC1)\n",
    "plt.xlabel(\"Residue number\")\n",
    "plt.ylabel(\"Contribution to PC1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2_ca_contributions = []\n",
    "for i in pca_obj.feature_PC_correlation[:,1]:\n",
    "    pc2_ca_contributions.append(np.absolute(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2_ca_X = np.array(pc2_ca_contributions[0:len(pc2_ca_contributions):3])\n",
    "pc2_ca_Y = np.array(pc2_ca_contributions[1:len(pc2_ca_contributions):3])\n",
    "pc2_ca_Z = np.array(pc2_ca_contributions[2:len(pc2_ca_contributions):3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC2_all_ca_contrib = np.vstack((pc2_ca_X,pc2_ca_Y,pc2_ca_Z)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_cont_PC2 = PC2_all_ca_contrib.sum(axis=1)\n",
    "summed_cont_PC2 = rearrange_data(summed_cont_PC2)\n",
    "np.savetxt(\"%s/PC2_atom_contribution.dat\" % filename , summed_cont_PC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(summed_cont_PC2)\n",
    "plt.xlabel(\"Residue number\")\n",
    "plt.ylabel(\"Contribution to PC2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pca_obj.eigenvalues.shape)\n",
    "print (pca_obj.eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 264 Ca atoms x each has 3 dimensions (x,y,z)\n",
    "#print \"1\" , pca_obj.eigenvalues.shape\n",
    "print (pca_obj.eigenvectors.shape)\n",
    "#subplot2grid((3,1),(0,0))\n",
    "#plt.plot(pca_obj.eigenvectors[:,0])\n",
    "subplot2grid((2,1),(0,0))\n",
    "plt.plot(pca_obj.eigenvectors[0])\n",
    "subplot2grid((2,1),(1,0))\n",
    "plt.plot(pca_obj.eigenvectors[1])\n",
    "plt.xlabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(pca_obj.eigenvectors[0])\n",
    "first_eigenvector = []\n",
    "for i in pca_obj.eigenvectors[0]:\n",
    "    first_eigenvector.append(i)\n",
    "    \n",
    "print (len(first_eigenvector))    \n",
    "print (\"Min value\")\n",
    "print (\"index\", first_eigenvector.index(min(first_eigenvector)))\n",
    "print (min(first_eigenvector))\n",
    "print (\"Max value\")\n",
    "print (\"index\" , first_eigenvector.index(max(first_eigenvector)))\n",
    "print (max(first_eigenvector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"First 10 PCs with 40k ss each for first sim\" ),( system_A_pca_out.shape)\n",
    "print (\"First PC for first input sim\"),( system_A_pca_out[:,0])\n",
    "print (\"Second PC for first input sim\"),( system_A_pca_out[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of pc1 and pc2\n",
    "plt.plot(pca_obj.eigenvectors[0],pca_obj.eigenvectors[1], marker='.', lw=0)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.xlim(-0.3,0.3)\n",
    "plt.ylim(-0.3,0.3)\n",
    "plt.savefig('%s/1st_2nd_eigenvec_2d_plot.png' % filename)\n",
    "\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_variance = []\n",
    "total = sum(pca_obj.eigenvalues)\n",
    "\n",
    "\n",
    "for i in xrange(0,10):\n",
    "    first = pca_obj.eigenvalues[i]\n",
    "    x = first/total * 100\n",
    "    percentage_variance.append(x)\n",
    "    print (\"Percentage variance PC%s: \" % (i+1) , x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sum(percentage_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.linspace(1 , len(percentage_variance), num=len(percentage_variance))\n",
    "plt.plot(index,percentage_variance)\n",
    "plt.ylabel(\"Percentage variance\")\n",
    "plt.xlabel(\"Principal component\")\n",
    "plt.savefig(\"%s/variance.png\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of PC1 and PC2 vs. snapshot\n",
    "subplot2grid((2,1),(0,0))\n",
    "plt.plot(system_A_pca_out[:,0])\n",
    "plt.title(\"PC1 for each system\")\n",
    "plt.ylabel('PC1 system A')\n",
    "plt.ylim((-5 , 5))\n",
    "subplot2grid((2,1),(1,0))\n",
    "plt.plot(system_B_pca_out[:,0])\n",
    "plt.ylabel('PC1 system B')\n",
    "plt.ylim((-5 , 5))\n",
    "plt.savefig('%s/PC1_sysA_and_B_vs_ss.png' % filename)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of PC1 and PC2 vs. snapshot\n",
    "subplot2grid((2,1),(0,0))\n",
    "plt.plot(system_C_pca_out[:,0])\n",
    "plt.title(\"PC1 for each system\")\n",
    "plt.ylabel('PC1 system C')\n",
    "plt.ylim((-5 , 5))\n",
    "subplot2grid((2,1),(1,0))\n",
    "plt.plot(system_D_pca_out[:,0])\n",
    "plt.ylabel('PC1 system D')\n",
    "plt.ylim((-5 , 5))\n",
    "plt.savefig('%s/PC1_sysC_and_D_vs_ss.png' % filename)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of PC1 and PC2 vs. snapshot\n",
    "subplot2grid((2,1),(0,0))\n",
    "plt.plot(system_A_pca_out[:,1])\n",
    "plt.title(\"PC2 for each system\")\n",
    "plt.ylabel('PC2 system A')\n",
    "plt.ylim((-5 , 5))\n",
    "subplot2grid((2,1),(1,0))\n",
    "plt.plot(system_B_pca_out[:,1])\n",
    "plt.ylabel('PC2 system B')\n",
    "plt.ylim((-5 , 5))\n",
    "plt.savefig('%s/PC2_sysA_and_B_vs_ss.png' % filename)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of PC1 and PC2 vs. snapshot\n",
    "subplot2grid((2,1),(0,0))\n",
    "plt.plot(system_C_pca_out[:,1])\n",
    "plt.title(\"PC2 for each system\")\n",
    "plt.ylabel('PC2 system C')\n",
    "plt.ylim((-5 , 5))\n",
    "subplot2grid((2,1),(1,0))\n",
    "plt.plot(system_D_pca_out[:,1])\n",
    "plt.ylabel('PC2 system D')\n",
    "plt.ylim((-5 , 5))\n",
    "plt.savefig('%s/PC2_sysC_and_D_vs_ss.png' % filename)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.vstack((system_A_pca_out[:,0],system_B_pca_out[:,0],system_C_pca_out[:,0],system_D_pca_out[:,0])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1_all = np.vstack((system_A_pca_out[:,0],system_B_pca_out[:,0],system_C_pca_out[:,0],system_D_pca_out[:,0])).reshape(inp.n_frames_total(),)\n",
    "pc2_all = np.vstack((system_A_pca_out[:,1],system_B_pca_out[:,1],system_C_pca_out[:,1],system_D_pca_out[:,1])).reshape(inp.n_frames_total(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_,x_,y_ = np.histogram2d(pc1_all,pc2_all, bins=50, range=[[-5, 5], [-5, 5]])\n",
    "plot_surface = [x_[0], x_[-1], y_[0], y_[-1]]\n",
    "plt.contourf(z_.T, 100, extent=plot_surface)\n",
    "plt.xlim(-4,3)\n",
    "plt.ylim(-3,4)\n",
    "plt.savefig('%s/2dhistogram.png' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_,x_,y_ = np.histogram2d(pc1_all,pc2_all, bins=50, range=[[-5, 5], [-5, 5]])\n",
    "plot_surface = [x_[0], x_[-1], y_[0], y_[-1]]\n",
    "plt.contourf(z_.T, 100, extent=plot_surface)\n",
    "\n",
    "plt.plot(system_A_pca_out[:,0][0::500],system_A_pca_out[:,1][0::500], marker='_', color='r')\n",
    "plt.plot(system_B_pca_out[:,0][0::500],system_B_pca_out[:,1][0::500], marker='_', color='w')\n",
    "plt.plot(system_C_pca_out[:,0][0::500],system_C_pca_out[:,1][0::500], marker='_', color='y')\n",
    "plt.plot(system_D_pca_out[:,0][0::500],system_D_pca_out[:,1][0::500], marker='_', color='g')\n",
    "plt.xlim(-4,3)\n",
    "plt.ylim(-3,4)\n",
    "plt.savefig('%s/2dhistogram_TRAJ.png' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_list_pc1 = []\n",
    "min_max_list_pc2 = []\n",
    "\n",
    "min_max_list_pc1.append(min(system_A_pca_out[:,0]))\n",
    "min_max_list_pc1.append(max(system_A_pca_out[:,0]))\n",
    "min_max_list_pc1.append(min(system_B_pca_out[:,0]))\n",
    "min_max_list_pc1.append(max(system_B_pca_out[:,0]))\n",
    "\n",
    "min_max_list_pc1.append(min(system_C_pca_out[:,0]))\n",
    "min_max_list_pc1.append(max(system_C_pca_out[:,0]))\n",
    "min_max_list_pc1.append(min(system_D_pca_out[:,0]))\n",
    "min_max_list_pc1.append(max(system_D_pca_out[:,0]))\n",
    "\n",
    "min_max_list_pc2.append(min(system_A_pca_out[:,1]))\n",
    "min_max_list_pc2.append(max(system_A_pca_out[:,1]))\n",
    "min_max_list_pc2.append(min(system_B_pca_out[:,1]))\n",
    "min_max_list_pc2.append(max(system_B_pca_out[:,1]))\n",
    "\n",
    "min_max_list_pc2.append(min(system_C_pca_out[:,1]))\n",
    "min_max_list_pc2.append(max(system_D_pca_out[:,1]))\n",
    "min_max_list_pc2.append(min(system_D_pca_out[:,1]))\n",
    "min_max_list_pc2.append(max(system_D_pca_out[:,1]))\n",
    "\n",
    "bin_max_pc1 = int((max(min_max_list_pc1))+1)\n",
    "bin_min_pc1 = int((min(min_max_list_pc1))-1)\n",
    "bin_max_pc2 = int((max(min_max_list_pc2))+1)\n",
    "bin_min_pc2 = int((min(min_max_list_pc2))-1)\n",
    "\n",
    "print (\"Bin range will be from %s to %s for PC1\" % (bin_min_pc1,bin_max_pc1))\n",
    "print (\"Bin range will be from %s to %s for PC2\" % (bin_min_pc2,bin_max_pc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can then output distributions of PC1 and PC2 for kL/MI etc. \n",
    "\n",
    "sysA = plt.hist(system_A_pca_out[:,0], bins=100, range=(bin_min_pc1,bin_max_pc1), normed=True, histtype='step', color='r', label='A')\n",
    "sysB = plt.hist(system_B_pca_out[:,0], bins=100, range=(bin_min_pc1,bin_max_pc1), normed=True, histtype='step', color='b', label='B')\n",
    "sysB = plt.hist(system_C_pca_out[:,0], bins=100, range=(bin_min_pc1,bin_max_pc1), normed=True, histtype='step', color='y', label='C')\n",
    "sysB = plt.hist(system_D_pca_out[:,0], bins=100, range=(bin_min_pc1,bin_max_pc1), normed=True, histtype='step', color='g', label='D')\n",
    "\n",
    "plt.ylim(0,3)\n",
    "plt.xlim(bin_min_pc1,bin_max_pc1)\n",
    "pylab.legend(loc='upper left')\n",
    "plt.savefig('%s/PC1_histogram.png' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysA = plt.hist(system_A_pca_out[:,1], bins=100, range=(bin_min_pc2,bin_max_pc2), normed=True, histtype='step', color='r', label='A')\n",
    "sysB = plt.hist(system_B_pca_out[:,1], bins=100, range=(bin_min_pc2,bin_max_pc2), normed=True, histtype='step', color='b', label='B')\n",
    "sysB = plt.hist(system_C_pca_out[:,1], bins=100, range=(bin_min_pc2,bin_max_pc2), normed=True, histtype='step', color='y', label='C')\n",
    "sysB = plt.hist(system_D_pca_out[:,1], bins=100, range=(bin_min_pc2,bin_max_pc2), normed=True, histtype='step', color='g', label='D')\n",
    "\n",
    "plt.ylim(0,3)\n",
    "plt.xlim(bin_min_pc2,bin_max_pc2)\n",
    "pylab.legend(loc='upper left')\n",
    "plt.savefig('%s/PC2_histogram.png' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sys = [system_A_pca_out , system_B_pca_out , system_C_pca_out , system_D_pca_out]    \n",
    "list_of_names = [\"system_A\" , \"system_B\" , \"system_C\" , \"system_D\"]\n",
    "\n",
    "# Save PC per shapshot for each system for MI calc\n",
    "for p in range(0, len(list_of_sys)):\n",
    "    list_of_sys[p][:,0].save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sys = [system_A_pca_out , system_B_pca_out , system_C_pca_out , system_D_pca_out]    \n",
    "list_of_names = [\"system_A\" , \"system_B\" , \"system_C\" , \"system_D\"]\n",
    "\n",
    "for p in range(0, len(list_of_sys)):\n",
    "    np.savetxt(\"%s/PC1_raw_data_%s.dat\" % (filename,list_of_names[p]) , list_of_sys[p][:,0])\n",
    "    (n, bins) = np.histogram(list_of_sys[p][:,0], bins = 100, range=(bin_min_pc1,bin_max_pc1), normed=True)\n",
    "    n = n / (sum(n))\n",
    "    bincentre = 0.5*(bins[1:]+bins[:-1])\n",
    "    index = np.linspace(1, len(bincentre), num = len(bincentre), dtype = int)\n",
    "    # Add to empty bins only - amount added is equal to 1/(number empty bins) - to allow calculation of KL\n",
    "    total_bin_addition = 0.000001\n",
    "    all_bins = len(bincentre)\n",
    "    # To count the number of populated and non populated bins, to allow dividion of the total bin addition\n",
    "    non_zero = np.count_nonzero(n)\n",
    "    print (\"Number of populated bins:\"), (non_zero)\n",
    "    zero_bins = all_bins - non_zero\n",
    "    print (\"Number of zero bins:\"), (zero_bins)\n",
    "    bin_addition = total_bin_addition/float(zero_bins)\n",
    "    print (\"Amount added to empty bins:\"), (bin_addition)\n",
    "    for i in xrange(len(n)):\n",
    "        if n[i]==0.0:\n",
    "            n[i] = bin_addition\n",
    "    data = np.vstack((index, n)).T\n",
    "    np.savetxt(\"%s/PC1_hist_%s.dat\" % (filename,list_of_names[p]) , data, fmt=['%d', '%.20f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(0, len(list_of_sys)):\n",
    "    np.savetxt(\"%s/PC2_raw_data_%s.dat\" % (filename,list_of_names[p]) , list_of_sys[p][:,1])\n",
    "    (n, bins) = np.histogram(list_of_sys[p][:,1], bins = 100, range=(bin_min_pc2,bin_max_pc2), normed=True)\n",
    "    n = n / (sum(n))\n",
    "    bincentre = 0.5*(bins[1:]+bins[:-1])\n",
    "    index = np.linspace(1, len(bincentre), num = len(bincentre), dtype = int)\n",
    "    # Add to empty bins only - amount added is equal to 1/(number empty bins) - to allow calculation of KL\n",
    "    total_bin_addition = 0.000001\n",
    "    all_bins = len(bincentre)\n",
    "    # To count the number of populated and non populated bins, to allow dividion of the total bin addition\n",
    "    non_zero = np.count_nonzero(n)\n",
    "    print (\"Number of populated bins:\"), (non_zero)\n",
    "    zero_bins = all_bins - non_zero\n",
    "    print (\"Number of zero bins:\"), (zero_bins)\n",
    "    bin_addition = total_bin_addition/float(zero_bins)\n",
    "    print (\"Amount added to empty bins: \"), (bin_addition)\n",
    "    for i in xrange(len(n)):\n",
    "        if n[i]==0.0:\n",
    "            n[i] = bin_addition\n",
    "    data = np.vstack((index, n)).T\n",
    "    np.savetxt(\"%s/PC2_hist_%s.dat\" % (filename,list_of_names[p]) , data, fmt=['%d', '%.20f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pymol session to see per atom contribution and min max of each system\n",
    "\n",
    "White: Does not contribute to PC\n",
    "\n",
    "Grey: Medium contribution to PC\n",
    "\n",
    "Red: Highest contribution to PC\n",
    "\n",
    "Run from the folder CA_COOR_OUTPUT:\n",
    "\n",
    "**`pymol ../../Scripts/8_alter_B_factor.pml`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"z_images/pymol_session_PCA.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
