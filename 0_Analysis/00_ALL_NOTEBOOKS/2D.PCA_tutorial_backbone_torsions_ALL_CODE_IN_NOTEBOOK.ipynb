{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "Need to change torsion input to sin/cos pair as need average for pca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA analysis\n",
    "\n",
    "### Torsion PCA\n",
    "\n",
    "### Need one trajectory for each system and align ALL to the same reference with cpptraj. All traj should have same topology. So remove all water, ligands, etc.\n",
    "\n",
    "for this tutorial, use longer trajectories (40,000 frames each) and also use 2 more simulations (apo - no allosteric ligand, and otu - another activator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic(u'pylab inline')\n",
    "import pyemma\n",
    "import pyemma.coordinates as coor\n",
    "from pyemma.coordinates import pca\n",
    "import mdtraj as md\n",
    "from pyemma.coordinates import load\n",
    "from pyemma.coordinates import source\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0_system_A (PDK1 with allosteric inhibitor 1F8 bound. PDB ID 3ORX)\n",
    "\n",
    "1_system_B (PDK1 with allosteric activator 2A2 bound. PDB ID 3ORZ.)\n",
    "\n",
    "2_system_C (PDK1 with no allosteric ligand bound - 3orx structure with ligand removed)\n",
    "\n",
    "3_system_D (PDK1 with allosteric activator J30 bound. PDB ID 3OTU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit system_list with folder names of different systems.\n",
    "system_list = [\"0_system_A\",\"1_system_B\",\"2_system_C\",\"3_system_D\"]\n",
    "md_data = \"0_TRAJECTORIES\"\n",
    "#traj_filename = \"longtraj_aligned_PCA.dcd\"\n",
    "traj_filename = \"short_traj_aligned.dcd\"\n",
    "top = \"%s/%s/topology.parm7\" % (md_data,system_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a list with all file locations of trajectory data\n",
    "all_files_list = []\n",
    "\n",
    "for i in range(0,len(system_list)):\n",
    "    filenames = \"%s/%s/%s\" % (md_data,system_list[i],traj_filename)\n",
    "    all_files_list.append(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (all_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"2_PCA/TORSION_OUTPUT\" \n",
    "if not os.path.exists(filename):\n",
    "    cmd = \"mkdir -p %s\" % filename\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topology = md.load_prmtop(top)\n",
    "\n",
    "print (topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only CA and also not all residues - C-terminal region is large. \n",
    "# This is approx focus on residues around active site, around allosteric site, and between\n",
    "\n",
    "# all CA indices:\n",
    "CA_topo = topology.select(\"name CA\")\n",
    "\n",
    "# selected CA indices\n",
    "atom_selection = topology.select('backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = coor.featurizer(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.add_backbone_torsions()\n",
    "inp = coor.source([all_files_list[0],all_files_list[1],all_files_list[2],all_files_list[3]], features=feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('trajectory length = ',inp.trajectory_length(0))\n",
    "print ('number of dimensions = ',inp.dimension())\n",
    "print ('number of trajectories =', inp.number_of_trajectories())\n",
    "print ('total number of frames = ', inp.n_frames_total())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_obj = coor.pca(inp, dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "system_A_pca_out = pca_obj.get_output()[0]\n",
    "system_B_pca_out = pca_obj.get_output()[1]\n",
    "system_C_pca_out = pca_obj.get_output()[2]\n",
    "system_D_pca_out = pca_obj.get_output()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pc1, min and mac values are these frames:\n",
    "A_pc1_max = (argmax(system_A_pca_out[:,0]))\n",
    "A_pc1_min = (argmin(system_A_pca_out[:,0]))\n",
    "\n",
    "B_pc1_max = (argmax(system_B_pca_out[:,0]))\n",
    "B_pc1_min = (argmin(system_B_pca_out[:,0]))\n",
    "\n",
    "C_pc1_max = (argmax(system_C_pca_out[:,0]))\n",
    "C_pc1_min = (argmin(system_C_pca_out[:,0]))\n",
    "\n",
    "D_pc1_max = (argmax(system_D_pca_out[:,0]))\n",
    "D_pc1_min = (argmin(system_D_pca_out[:,0]))\n",
    "\n",
    "system_A_traj = md.load(all_files_list[0],top=topology)\n",
    "system_B_traj = md.load(all_files_list[1],top=topology)\n",
    "system_C_traj = md.load(all_files_list[2],top=topology)\n",
    "system_D_traj = md.load(all_files_list[3],top=topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_A_traj[A_pc1_max].save_pdb(\"%s/A_PC1_max_frame%s.pdb\" % (filename,A_pc1_max))\n",
    "system_A_traj[A_pc1_min].save_pdb(\"%s/A_PC1_min_frame%s.pdb\" % (filename,A_pc1_min))\n",
    "\n",
    "system_B_traj[B_pc1_max].save_pdb(\"%s/B_PC1_max_frame%s.pdb\" % (filename,B_pc1_max))\n",
    "system_B_traj[B_pc1_min].save_pdb(\"%s/B_PC1_min_frame%s.pdb\" % (filename,B_pc1_min))\n",
    "\n",
    "system_C_traj[C_pc1_max].save_pdb(\"%s/C_PC1_max_frame%s.pdb\" % (filename,C_pc1_max))\n",
    "system_C_traj[C_pc1_min].save_pdb(\"%s/C_PC1_min_frame%s.pdb\" % (filename,C_pc1_min))\n",
    "\n",
    "system_D_traj[D_pc1_max].save_pdb(\"%s/D_PC1_max_frame%s.pdb\" % (filename,D_pc1_max))\n",
    "system_D_traj[D_pc1_min].save_pdb(\"%s/D_PC1_min_frame%s.pdb\" % (filename,D_pc1_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per dimension contribution to PCA\n",
    "#inp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since we don't need to include all residues in the PCA, we need to assign the per atom contribution to the \n",
    "# correct residue in the topology. To do this, rearrange the data by adding zeros for residues not included in the PCA\n",
    "\n",
    "def rearrange_data(data):\n",
    "    residue_and_per_atom_contribution = np.vstack((atom_selection,data)).T\n",
    "    new_atoms = []\n",
    "    for i in CA_topo:\n",
    "        if i in atom_selection: \n",
    "            new_atoms.append(i)\n",
    "        else:\n",
    "            new_atoms.append(\"--\")\n",
    "    new_data = []\n",
    "    j = 0\n",
    "    for i in range (0,len(CA_topo)):\n",
    "        if CA_topo[i] in residue_and_per_atom_contribution[:,0]:\n",
    "            new_data.append(residue_and_per_atom_contribution[j][1])\n",
    "            j = j + 1 \n",
    "        else:\n",
    "            new_data.append(0.0)\n",
    "    return new_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1_ca_contributions = np.absolute(pca_obj.feature_PC_correlation[:,0].reshape(len(pca_obj.feature_PC_correlation[:,0]),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per residue contribution will be sum of every 2 values (since Psi+Phi for each residue)\n",
    "summed_cont_PC1 = np.add.reduceat(pc1_ca_contributions, np.arange(0, len(pc1_ca_contributions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"%s/PC1_atom_contribution.dat\" % filename,summed_cont_PC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(summed_cont_PC1)\n",
    "plt.xlabel(\"Residue number\")\n",
    "plt.ylabel(\"Contribution to PC1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc2_ca_contributions = np.absolute(pca_obj.feature_PC_correlation[:,1].reshape(len(pca_obj.feature_PC_correlation[:,1]),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Per residue contribution will be sum of every 2 values (since Psi+Phi for each residue)\n",
    "summed_cont_PC2 = np.add.reduceat(pc2_ca_contributions, np.arange(0, len(pc2_ca_contributions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"%s/PC2_atom_contribution.dat\" % filename,summed_cont_PC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(summed_cont_PC2)\n",
    "plt.xlabel(\"Residue number\")\n",
    "plt.ylabel(\"Contribution to PC2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 264 Ca atoms x each has 3 dimensions (x,y,z)\n",
    "#print \"1\" , pca_obj.eigenvalues.shape\n",
    "print (pca_obj.eigenvectors.shape)\n",
    "#subplot2grid((3,1),(0,0))\n",
    "#plt.plot(pca_obj.eigenvectors[:,0])\n",
    "subplot2grid((2,1),(0,0))\n",
    "plt.plot(pca_obj.eigenvectors[0])\n",
    "subplot2grid((2,1),(1,0))\n",
    "plt.plot(pca_obj.eigenvectors[1])\n",
    "plt.xlabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(pca_obj.eigenvectors[0])\n",
    "first_eigenvector = []\n",
    "for i in pca_obj.eigenvectors[0]:\n",
    "    first_eigenvector.append(i)\n",
    "    \n",
    "print (len(first_eigenvector))    \n",
    "print (\"Min value\")\n",
    "print (\"index\", first_eigenvector.index(min(first_eigenvector)))\n",
    "print (min(first_eigenvector))\n",
    "print (\"Max value\")\n",
    "print (\"index\" , first_eigenvector.index(max(first_eigenvector)))\n",
    "print (max(first_eigenvector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"First 10 PCs with 40k ss each for first sim\" , system_A_pca_out.shape)\n",
    "print (\"First PC for first input sim\", system_A_pca_out[:,0])\n",
    "print (\"Second PC for first input sim\", system_A_pca_out[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of pc1 and pc2\n",
    "plt.plot(pca_obj.eigenvectors[0],pca_obj.eigenvectors[1], marker='.', lw=0)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.xlim(-0.3,0.3)\n",
    "plt.ylim(-0.3,0.3)\n",
    "plt.savefig('%s/1st_2nd_eigenvec_2d_plot.png' % filename)\n",
    "\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_variance = []\n",
    "total = sum(pca_obj.eigenvalues)\n",
    "\n",
    "\n",
    "for i in xrange(0,10):\n",
    "    first = pca_obj.eigenvalues[i]\n",
    "    x = first/total * 100\n",
    "    percentage_variance.append(x)\n",
    "    print (\"Percentage variance PC%s: \" % (i+1) , x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sum(percentage_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.linspace(1 , len(percentage_variance), num=len(percentage_variance))\n",
    "plt.plot(index,percentage_variance)\n",
    "plt.ylabel(\"Percentage variance\")\n",
    "plt.xlabel(\"Principal component\")\n",
    "plt.savefig(\"%s/variance.png\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of PC1 and PC2 vs. snapshot\n",
    "subplot2grid((2,1),(0,0))\n",
    "plt.plot(system_A_pca_out[:,0])\n",
    "plt.title(\"PC1 for each system\")\n",
    "plt.ylabel('PC1 system A')\n",
    "plt.ylim((-10 , 20))\n",
    "subplot2grid((2,1),(1,0))\n",
    "plt.plot(system_B_pca_out[:,0])\n",
    "plt.ylabel('PC1 system B')\n",
    "plt.ylim((-10 , 20))\n",
    "plt.savefig('%s/PC1_sysA_and_B_vs_ss.png' % filename)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of PC1 and PC2 vs. snapshot\n",
    "subplot2grid((2,1),(0,0))\n",
    "plt.plot(system_C_pca_out[:,0])\n",
    "plt.title(\"PC1 for each system\")\n",
    "plt.ylabel('PC1 system C')\n",
    "plt.ylim((-10 , 20))\n",
    "subplot2grid((2,1),(1,0))\n",
    "plt.plot(system_D_pca_out[:,0])\n",
    "plt.ylabel('PC1 system D')\n",
    "plt.ylim((-10 , 20))\n",
    "plt.savefig('%s/PC1_sysC_and_D_vs_ss.png' % filename)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of PC1 and PC2 vs. snapshot\n",
    "subplot2grid((2,1),(0,0))\n",
    "plt.plot(system_A_pca_out[:,1])\n",
    "plt.title(\"PC2 for each system\")\n",
    "plt.ylabel('PC2 system A')\n",
    "plt.ylim((-10 , 10))\n",
    "subplot2grid((2,1),(1,0))\n",
    "plt.plot(system_B_pca_out[:,1])\n",
    "plt.ylabel('PC2 system B')\n",
    "plt.ylim((-10 , 10))\n",
    "plt.savefig('%s/PC2_sysA_and_B_vs_ss.png' % filename)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of PC1 and PC2 vs. snapshot\n",
    "subplot2grid((2,1),(0,0))\n",
    "plt.plot(system_C_pca_out[:,1])\n",
    "plt.title(\"PC2 for each system\")\n",
    "plt.ylabel('PC2 system C')\n",
    "plt.ylim((-10 , 10))\n",
    "subplot2grid((2,1),(1,0))\n",
    "plt.plot(system_D_pca_out[:,1])\n",
    "plt.ylabel('PC2 system D')\n",
    "plt.ylim((-10 , 10))\n",
    "plt.savefig('%s/PC2_sysC_and_D_vs_ss.png' % filename)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.vstack((system_A_pca_out[:,0],system_B_pca_out[:,0],system_C_pca_out[:,0],system_D_pca_out[:,0])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc1_all = np.vstack((system_A_pca_out[:,0],system_B_pca_out[:,0],system_C_pca_out[:,0],system_D_pca_out[:,0])).reshape(inp.n_frames_total(),)\n",
    "pc2_all = np.vstack((system_A_pca_out[:,1],system_B_pca_out[:,1],system_C_pca_out[:,1],system_D_pca_out[:,1])).reshape(inp.n_frames_total(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_,x_,y_ = np.histogram2d(pc1_all,pc2_all, bins=50, range=[[-10, 20], [-10, 10]])\n",
    "plot_surface = [x_[0], x_[-1], y_[0], y_[-1]]\n",
    "plt.contourf(z_.T, 100, extent=plot_surface)\n",
    "plt.xlim(-10,20)\n",
    "plt.ylim(-10,10)\n",
    "plt.savefig('%s/2dhistogram.png' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_,x_,y_ = np.histogram2d(pc1_all,pc2_all, bins=50, range=[[-10, 20], [-10, 10]])\n",
    "plot_surface = [x_[0], x_[-1], y_[0], y_[-1]]\n",
    "plt.contourf(z_.T, 100, extent=plot_surface)\n",
    "\n",
    "plt.plot(system_A_pca_out[:,0][0::50],system_A_pca_out[:,1][0::50], marker='_', color='r')\n",
    "plt.plot(system_B_pca_out[:,0][0::50],system_B_pca_out[:,1][0::50], marker='_', color='w')\n",
    "plt.plot(system_C_pca_out[:,0][0::50],system_C_pca_out[:,1][0::50], marker='_', color='y')\n",
    "plt.plot(system_D_pca_out[:,0][0::50],system_D_pca_out[:,1][0::50], marker='_', color='g')\n",
    "plt.xlim(-10,20)\n",
    "plt.ylim(-10,10)\n",
    "plt.savefig('%s/2dhistogram_TRAJ.png' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_list_pc1 = []\n",
    "min_max_list_pc2 = []\n",
    "\n",
    "min_max_list_pc1.append(min(system_A_pca_out[:,0]))\n",
    "min_max_list_pc1.append(max(system_A_pca_out[:,0]))\n",
    "min_max_list_pc1.append(min(system_B_pca_out[:,0]))\n",
    "min_max_list_pc1.append(max(system_B_pca_out[:,0]))\n",
    "\n",
    "min_max_list_pc1.append(min(system_C_pca_out[:,0]))\n",
    "min_max_list_pc1.append(max(system_C_pca_out[:,0]))\n",
    "min_max_list_pc1.append(min(system_D_pca_out[:,0]))\n",
    "min_max_list_pc1.append(max(system_D_pca_out[:,0]))\n",
    "\n",
    "min_max_list_pc2.append(min(system_A_pca_out[:,1]))\n",
    "min_max_list_pc2.append(max(system_A_pca_out[:,1]))\n",
    "min_max_list_pc2.append(min(system_B_pca_out[:,1]))\n",
    "min_max_list_pc2.append(max(system_B_pca_out[:,1]))\n",
    "\n",
    "min_max_list_pc2.append(min(system_C_pca_out[:,1]))\n",
    "min_max_list_pc2.append(max(system_D_pca_out[:,1]))\n",
    "min_max_list_pc2.append(min(system_D_pca_out[:,1]))\n",
    "min_max_list_pc2.append(max(system_D_pca_out[:,1]))\n",
    "\n",
    "bin_max_pc1 = int((max(min_max_list_pc1))+1)\n",
    "bin_min_pc1 = int((min(min_max_list_pc1))-1)\n",
    "bin_max_pc2 = int((max(min_max_list_pc2))+1)\n",
    "bin_min_pc2 = int((min(min_max_list_pc2))-1)\n",
    "\n",
    "print (\"Bin range will be from %s to %s for PC1\" % (bin_min_pc1,bin_max_pc1))\n",
    "print (\"Bin range will be from %s to %s for PC2\" % (bin_min_pc2,bin_max_pc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can then output distributions of PC1 and PC2 for kL/MI etc. \n",
    "\n",
    "sysA = plt.hist(system_A_pca_out[:,0], bins=100, normed=True, histtype='step', color='r', label='A')\n",
    "sysB = plt.hist(system_B_pca_out[:,0], bins=100, normed=True, histtype='step', color='b', label='B')\n",
    "sysC = plt.hist(system_C_pca_out[:,0], bins=100, normed=True, histtype='step', color='y', label='C')\n",
    "sysD = plt.hist(system_D_pca_out[:,0], bins=100, normed=True, histtype='step', color='g', label='D')\n",
    "\n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(bin_min_pc1,bin_max_pc1)\n",
    "pylab.legend(loc='upper left')\n",
    "plt.savefig('%s/PC1_histogram.png' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysA = plt.hist(system_A_pca_out[:,1], bins=100, normed=True, histtype='step', color='r', label='A')\n",
    "sysB = plt.hist(system_B_pca_out[:,1], bins=100, normed=True, histtype='step', color='b', label='B')\n",
    "sysC = plt.hist(system_C_pca_out[:,1], bins=100, normed=True, histtype='step', color='y', label='C')\n",
    "sysD = plt.hist(system_D_pca_out[:,1], bins=100, normed=True, histtype='step', color='g', label='D')\n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(bin_min_pc2,bin_max_pc2)\n",
    "pylab.legend(loc='upper left')\n",
    "plt.savefig('%s/PC2_histogram.png' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sys = [system_A_pca_out , system_B_pca_out , system_C_pca_out , system_D_pca_out]    \n",
    "list_of_names = [\"system_A\" , \"system_B\" , \"system_C\" , \"system_D\"]\n",
    "for p in range(0, len(list_of_sys)):\n",
    "    (n, bins) = np.histogram(list_of_sys[p][:,0], bins = 100, range=(bin_min_pc1,bin_max_pc1), normed=True)\n",
    "    n = n / (sum(n))\n",
    "    bincentre = 0.5*(bins[1:]+bins[:-1])\n",
    "    index = np.linspace(1, len(bincentre), num = len(bincentre), dtype = int)\n",
    "    # Add to empty bins only - amount added is equal to 1/(number empty bins) - to allow calculation of KL\n",
    "    total_bin_addition = 0.000001\n",
    "    all_bins = len(bincentre)\n",
    "    # To count the number of populated and non populated bins, to allow dividion of the total bin addition\n",
    "    non_zero = np.count_nonzero(n)\n",
    "    print (\"Number of populated bins:\", non_zero)\n",
    "    zero_bins = all_bins - non_zero\n",
    "    print (\"Number of zero bins:\", zero_bins)\n",
    "    bin_addition = total_bin_addition/float(zero_bins)\n",
    "    print (\"Amount added to empty bins: \", bin_addition)\n",
    "    for i in xrange(len(n)):\n",
    "        if n[i]==0.0:\n",
    "            n[i] = bin_addition\n",
    "    data = np.vstack((index, n)).T\n",
    "    np.savetxt(\"%s/PC1_hist_%s.dat\" % (filename,list_of_names[p]) , data, fmt=['%d', '%.20f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(0, len(list_of_sys)):\n",
    "    (n, bins) = np.histogram(list_of_sys[p][:,1], bins = 100, range=(bin_min_pc2,bin_max_pc2), normed=True)\n",
    "    n = n / (sum(n))\n",
    "    bincentre = 0.5*(bins[1:]+bins[:-1])\n",
    "    index = np.linspace(1, len(bincentre), num = len(bincentre), dtype = int)\n",
    "    # Add to empty bins only - amount added is equal to 1/(number empty bins) - to allow calculation of KL\n",
    "    total_bin_addition = 0.000001\n",
    "    all_bins = len(bincentre)\n",
    "    # To count the number of populated and non populated bins, to allow dividion of the total bin addition\n",
    "    non_zero = np.count_nonzero(n)\n",
    "    print (\"Number of populated bins:\", non_zero)\n",
    "    zero_bins = all_bins - non_zero\n",
    "    print (\"Number of zero bins:\", zero_bins)\n",
    "    bin_addition = total_bin_addition/float(zero_bins)\n",
    "    print (\"Amount added to empty bins: \", bin_addition)\n",
    "    for i in xrange(len(n)):\n",
    "        if n[i]==0.0:\n",
    "            n[i] = bin_addition\n",
    "    data = np.vstack((index, n)).T\n",
    "    np.savetxt(\"%s/PC2_hist_%s.dat\" % (filename,list_of_names[p]) , data, fmt=['%d', '%.20f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PCA_torsion.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
